{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Copies files containing potentially valid \"rs\" terms from source to destination directory\n",
    "import os\n",
    "import shutil\n",
    "directory = \"/home/werner/Desktop/Source/articles.O-Z/\" #source directory\n",
    "filelisting = os.walk(directory)\n",
    "totalFiles = 0 #counter 1\n",
    "rsFiles = 0 #counter 2\n",
    "for root, dirs, files in filelisting:   \n",
    "    for file in files:\n",
    "        totalFiles += 1\n",
    "        breakTest = 0\n",
    "        fileOne = open(root + \"/\" + file)\n",
    "        if breakTest == 1:\n",
    "            break\n",
    "        for line in fileOne:\n",
    "            line1 = line.split()\n",
    "            if breakTest == 1:\n",
    "                break\n",
    "            for word in line1:\n",
    "                if (word.startswith('rs') or (not word[0].isalnum() and \"rs\" in word[1:3])): #search clause\n",
    "                    shutil.copy(os.path.join(root,file), \"/home/werner/Desktop/Destination/\" + file) #destination directory\n",
    "                    breakTest = 1\n",
    "                    rsFiles += 1\n",
    "                if breakTest == 1:\n",
    "                    break\n",
    "        fileOne.close()\n",
    "print(totalFiles, rsFiles) #print ratio of files scanned to files containing rsSNPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create flat file database\n",
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "import json\n",
    "import unicodedata\n",
    "def remove_control_characters(s): #Remove control characters in XML text\n",
    "    t = \"\"\n",
    "    for ch in s:\n",
    "        if unicodedata.category(ch)[0] == \"C\":\n",
    "            t += \" \"\n",
    "        if ch == \",\" or ch == \"\\\"\":\n",
    "            t += \"\"\n",
    "        else:\n",
    "            t += ch\n",
    "    return \"\".join(ch for ch in t if unicodedata.category(ch)[0]!=\"C\")\n",
    "directory = \"/home/werner/Desktop/Destination/\"\n",
    "filelisting = os.walk(directory)\n",
    "rslist =[]\n",
    "for root, dirs, files in filelisting:   \n",
    "    for file in files:\n",
    "        email = \"not available\" #iteration reset\n",
    "        pmid = \"not available\" #iteration reset\n",
    "        year = \"not available\" #iteration reset\n",
    "        doi = \"not available\" #iteration reset      \n",
    "        kwds = [] #iteration reset\n",
    "        title = \"\" #iteration reset\n",
    "        tree = ET.parse(root + \"/\" + file)\n",
    "        #Get email addresses\n",
    "        for node in tree.iter('email'):\n",
    "            email = node.text\n",
    "        #Get publication date\n",
    "        for node in tree.iter('pub-date'):\n",
    "            for subnode in node.iter('year'):\n",
    "                collection = node.attrib\n",
    "                if \"pub-type\" in collection.keys():\n",
    "                    year = subnode.text\n",
    "        #Get titles\n",
    "        for node in tree.iter('title-group'):\n",
    "            for subnode in node.iter('article-title'):\n",
    "                whole = subnode.itertext()\n",
    "                for parts in whole:\n",
    "                    title += parts\n",
    "        title = remove_control_characters(title)                \n",
    "        #Get PMC IDs\n",
    "        for node in tree.iter('article-id'):\n",
    "            pmidat = node.attrib\n",
    "            if \"pmc\" in pmidat.values():\n",
    "                pmid = node.text\n",
    "            if \"doi\" in pmidat.values():\n",
    "                doi = node.text   \n",
    "        #Get author defined keywords\n",
    "        for node in tree.iter('kwd'):  \n",
    "            kwd = node.text\n",
    "            if kwd != None:\n",
    "                kwds.append(json.dumps(kwd))  \n",
    "        kwdstring = str(kwds)\n",
    "        kwdstring = kwdstring.replace(\"'\", \"\")\n",
    "        kwdstring = kwdstring.replace(\"\\\\\", \"\")\n",
    "        #Get rs numbers\n",
    "        for node in tree.iter():\n",
    "            if node.text != None:\n",
    "                node = node.text.split()\n",
    "                for rsnumber in node:\n",
    "                    #trim rs numbers preceded by opening bracket\n",
    "                    if \"rs\" in rsnumber[1:3]:\n",
    "                        rsnumber = rsnumber[1:]\n",
    "                    #ensure that digits follow rs numbers and place limits on rs number length\n",
    "                    if rsnumber.isalnum() and len(rsnumber) > 4 and len(rsnumber) <= 12: \n",
    "                        #ensure that digits follow rs\n",
    "                        if rsnumber.startswith(\"rs\") and rsnumber[2].isdigit():\n",
    "                            #ensure that rs numbers end with digits\n",
    "                            while not rsnumber[-1].isdigit():\n",
    "                                rsnumber = rsnumber[:-1] \n",
    "                            #create list item without white spaces\n",
    "                            rslist.append(rsnumber.strip() + \"\\t\" + email.strip() + \"\\t\" + year.strip() + \\\n",
    "                            \"\\t\" + pmid.strip() + \"\\t\" + doi.strip() + \"\\t\" + file.strip() + \"\\t\" + str(kwdstring) + \"\\t\" + str(title))\n",
    "#create refSNP occurence counter (with dictionary) to avoid data duplication\n",
    "rsdict = {}\n",
    "for item in rslist:\n",
    "    #add data if counter is zero\n",
    "    if rsdict.get(item,\"empty\") == \"empty\":\n",
    "        rsdict.update({item:1})\n",
    "    #increment counter if data was added\n",
    "    if rsdict.get(item,\"empty\") != \"empty\":\n",
    "        rsdict[item] += 1\n",
    "rslist = []\n",
    "#create tab delimited CSV file and add data\n",
    "writetofile = open(\"/home/werner/Desktop/TEXTdb.csv\", \"a\")\n",
    "for item in rsdict.keys():\n",
    "    writetofile.write(item + \"\\t\" + str(rsdict[item]) + \"\\n\")\n",
    "writetofile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Convert tab delimited CSV file to JSON\n",
    "import json\n",
    "file = open(\"/home/werner/Desktop/TEXTdb.csv\", \"r\")\n",
    "JSONstring = \"{\\\"PMCOAI_rs_articles\\\": [\"\n",
    "for line in file:\n",
    "    lister = line.strip().split(\"\\t\")\n",
    "    if len(lister) == 9:\n",
    "        rs_number = \"\\\"rs_number\\\": \" + \"\\\"\" + lister[0] + \"\\\"\"\n",
    "        email_address = \"\\\"email_address\\\": \" + \"\\\"\" + lister[1] + \"\\\"\"\n",
    "        publication_date = \"\\\"publication_date\\\": \" + \"\\\"\" + lister[2] + \"\\\"\"\n",
    "        pubmed_id = \"\\\"pubmed_id\\\": \" + \"\\\"\" + lister[3] + \"\\\"\"\n",
    "        doi = \"\\\"doi\\\": \" + \"\\\"\" + lister[4] + \"\\\"\"\n",
    "        pubmed_file_name = \"\\\"pubmed_file_name\\\": \" + \"\\\"\" + lister[5] + \"\\\"\"\n",
    "        keywords = \"\\\"keywords\\\": \" + lister[6]\n",
    "        article_title = \"\\\"article_title\\\": \" + \"\\\"\" + lister[7] + \"\\\"\"\n",
    "        rs_number_cited_in_article = \"\\\"rs_number_cited_in_article\\\": \" + \"\\\"\" + lister[8] + \"\\\"\"   \n",
    "        newdictionary = \"{\" + rs_number + \", \" + email_address + \", \" + publication_date + \", \" + pubmed_id + \\\n",
    "        \", \" + doi + \", \" + pubmed_file_name + \", \" + rs_number_cited_in_article + \", \" + article_title + \", \" + keywords + \"}\"\n",
    "        JSONstring += newdictionary + \", \"\n",
    "file.close()\n",
    "#save JSON data and ensure last entry is enclosed in brackets\n",
    "with open(\"/home/werner/Desktop/JSONdbKeys.json\", \"w\") as file1:\n",
    "    JSONstring = JSONstring[:-2]\n",
    "    JSONstring += \"]}\"\n",
    "    file1.write(JSONstring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Generate keyword list and count keywords in database\n",
    "import json\n",
    "keywordList = []\n",
    "with open(\"/home/werner/Desktop/JSONdbKeys.json\") as data_file:    \n",
    "    data = json.load(data_file)\n",
    "    #Determine range to avoid out of bounds error\n",
    "    for i in range(len(data[\"PMCOAI_rs_articles\"])):\n",
    "        if len(data[\"PMCOAI_rs_articles\"][i][\"keywords\"]) > 0:\n",
    "            for keywords in data[\"PMCOAI_rs_articles\"][i][\"keywords\"]:\n",
    "                keywords = keywords.strip()\n",
    "                #Include alphanumeric terms and phrases\n",
    "                if len(keywords) > 0 and all(x.isalnum() or x.isspace() for x in keywords) \\\n",
    "                and not keywords.startswith(\"rs\"):\n",
    "                    keywordList.append(keywords)\n",
    "    #Remove duplicates with set\n",
    "    keywordList = set(keywordList)\n",
    "    #Revert to list\n",
    "    keywordList = sorted(keywordList)\n",
    "with open(\"/home/werner/Desktop/keywords.js\", \"w\") as data_file:\n",
    "    data_file.write(json.dumps(keywordList))\n",
    "print(len(keywordList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Generate rs number list and count rs numbers in database\n",
    "import json\n",
    "keywordList = []\n",
    "with open(\"/home/werner/Desktop/JSONdbKeys.json\") as data_file:    \n",
    "    data = json.load(data_file)\n",
    "    #Determine range to avoid out of bounds error\n",
    "    for i in range(len(data[\"PMCOAI_rs_articles\"])):\n",
    "        #Include rs numbers with at least four digits following \"rs\"\n",
    "        if len(data[\"PMCOAI_rs_articles\"][i][\"rs_number\"]) > 5 and data[\"PMCOAI_rs_articles\"][i][\"rs_number\"][2:].isdigit():\n",
    "            keywordList.append(data[\"PMCOAI_rs_articles\"][i][\"rs_number\"])\n",
    "    #Remove duplicates with set\n",
    "    keywordList = set(keywordList)\n",
    "    #Revert to list\n",
    "    keywordList = sorted(keywordList)\n",
    "with open(\"/home/werner/Desktop/rsnumbers.js\", \"w\") as data_file: \n",
    "    data_file.write(json.dumps(keywordList))\n",
    "print(len(keywordList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Return a list containing each object's DOI (using Python 3) if the object contains reference SNP ID rs5743810\n",
    "#Published on web page as example for API usage \n",
    "import httplib2\n",
    "import json\n",
    "h = httplib2.Http()\n",
    "resp, content = h.request(\"http://sniphunter.sanbi.ac.za/PMCOAI_rs_articles?rs_number=rs5743810\")\n",
    "assert resp.status == 200\n",
    "#Convert binary object to string\n",
    "result = content.decode(\"utf-8\")\n",
    "#Convert string to JSONstring\n",
    "inJSON = json.loads(result)\n",
    "for dictionary in inJSON:\n",
    "    for key, value in dictionary.items():\n",
    "        if key == \"doi\":\n",
    "            print(value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
